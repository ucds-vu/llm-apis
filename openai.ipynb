{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c3618a-2f8b-4d2c-8723-5fd3ce58a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "397c1abc-57e9-4653-adf8-d33f5e9c7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_instruction = \"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9788c725-d5c3-4311-8385-9c899bca9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"\"\"\n",
    "Explain the importance of low latency LLMs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dfac9ed-662f-4bd7-910b-41b7ba7fa352",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_API_KEY = \"\"\n",
    "GPT_MODEL = \"gpt-4o-mini\"\n",
    "TEMPERATURE = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a1bd38-a6ce-45d8-8b16-a67133e2424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=GPT_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9d1aaae-10b5-439a-bcce-84a20699012f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Low latency in large language models (LLMs) refers to the ability to generate responses quickly, with minimal delay between a user's input and the model's output. Here are several key reasons why low latency LLMs are important:\\n\\n1. **Real-time Applications**: In scenarios such as conversational AI, customer support, and virtual assistance, users expect immediate responses. Low latency ensures that interactions feel natural and fluid, enhancing user satisfaction and engagement.\\n\\n2. **User Experience**: Quick response times improve the overall user experience. Delays can lead to frustration, drop-offs, or negative perceptions of the technology. Smooth interactions encourage continued use.\\n\\n3. **Interactive Environments**: Low latency is crucial in interactive environments like games, interactive storytelling, and virtual reality. LLMs need to respond promptly to maintain immersion and engagement.\\n\\n4. **Scalability**: Low latency LLMs can handle a higher volume of requests simultaneously without causing bottlenecks. This scalability is essential for applications serving many users at once, such as cloud-based services.\\n\\n5. **Contextual Relevance**: In tasks requiring real-time understanding, such as live translation or real-time content moderation, low latency ensures that the model can maintain context and provide relevant responses without significant delays.\\n\\n6. **Competitive Edge**: In industries where timely information delivery is key (e.g., finance, news, entertainment), low latency can provide a competitive advantage, allowing organizations to respond to trends or customer needs faster than their competitors.\\n\\n7. **Collaborative Tasks**: For applications that involve collaboration, such as team brainstorming or editing documents, low latency allows for a seamless exchange of ideas and maintains momentum in discussions.\\n\\n8. **Feedback Loop**: In iterative workflows, where a user may rely on incremental feedback from an LLM, low latency supports rapid adjustments and refinements, leading to more effective outcomes.\\n\\n9. **AI Assistants**: In AI-driven personal assistants, low latency ensures that tasks such as setting reminders, answering queries, or controlling smart home devices happen promptly, closely mimicking human interaction.\\n\\n10. **Edge Computing**: As applications increasingly move towards edge computing, low latency becomes even more critical. Processing data closer to the user reduces transmission delays and enhances responsiveness.\\n\\nIn summary, low latency LLMs are essential for delivering an effective and satisfactory user experience across various applications, enabling real-time interaction, fostering engagement, and supporting dynamic use cases in numerous domains.\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=GPT_MODEL,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": assistant_instruction},\n",
    "    {\"role\": \"user\", \"content\": user_query}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb457927-8793-4c8a-9cb4-fd96a17d04a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "  name=\"ucds-test-2\",\n",
    "  instructions=assistant_instruction,\n",
    "  model=GPT_MODEL,\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3869be54-12fd-4371-81dc-6d1a82a039c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = client.vector_stores.create(name=\"Financial Statements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37b31084-c6da-4a09-a248-d43718cdd400",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\"rag_files/March_26.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "  vector_store_id=vector_store.id, files=file_streams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d51bbd9a-978d-4b5b-adee-e75646e487e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98a56ee0-a16d-4b6f-adeb-733febc71d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be118df6-cb00-4e32-a45e-176dd46a77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_query\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c537e05e-ace6-4e75-b624-b513e4521b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99148244-b050-462e-968f-a032567f5402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text(annotations=[], value=\"Low latency in large language models (LLMs) is crucial for several reasons:\\n\\n1. **User Experience**: In applications such as chatbots, virtual assistants, and live customer support, low latency is essential to provide real-time interactions. Users expect immediate responses, and high latency can lead to frustration and disengagement.\\n\\n2. **Productivity Enhancement**: In environments where LLMs are used to augment human decision-making or creative processes, such as content generation or data analysis, low latency can significantly enhance productivity. Faster responses allow users to iterate more quickly on ideas and decisions.\\n\\n3. **Real-Time Applications**: Applications requiring real-time data processing, such as gaming, financial trading platforms, and live transcription services, benefit from low latency to ensure timely information delivery. Delays can result in missed opportunities or inaccuracies in time-sensitive scenarios.\\n\\n4. **Interactive Learning**: For educational tools leveraging LLMs, low latency enables a more engaging and interactive experience. Immediate feedback can help learners stay motivated and effectively absorb information.\\n\\n5. **Scalability**: As LLMs are integrated into more applications, low latency becomes vital for meeting the demands of multiple users or sessions simultaneously. Efficient processing can enhance the model's scalability and usability across various platforms.\\n\\n6. **Cost Efficiency**: Faster processing times can lead to reduced computational costs, as tasks are completed more quickly and resources are utilized more efficiently.\\n\\n7. **Dynamic Contextual Understanding**: Low latency allows LLMs to interact seamlessly in dynamic contexts where topics may shift rapidly, such as in live discussions or debates. Quick comprehension and response are necessary to maintain coherence and relevance.\\n\\nOverall, low latency in LLMs is crucial for enhancing user satisfaction, improving operational efficiency, and enabling innovative applications across various domains.\")\n"
     ]
    }
   ],
   "source": [
    "print(message_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d759dd-e0e3-403e-a975-e91b806eff3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
